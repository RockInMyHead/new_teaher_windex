import { replaceNumbersInText } from './numbersToWords';

export interface TTSOptions {
  voice?: 'alloy' | 'echo' | 'fable' | 'onyx' | 'nova' | 'shimmer';
  speed?: number;
  model?: 'tts-1' | 'tts-1-hd';
  format?: 'aac' | 'mp3' | 'opus' | 'flac';
}

// –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è —ç–ª–µ–º–µ–Ω—Ç–∞ –æ—á–µ—Ä–µ–¥–∏ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è
interface AudioQueueItem {
  buffer: AudioBuffer;
  index: number;
  text: string;
}

export class OpenAITTS {
  private static audioContext: AudioContext | null = null;
  private static currentAudio: HTMLAudioElement | null = null;
  private static videoElement: HTMLVideoElement | null = null;
  private static currentAudioUrl: string | null = null;
  private static interactionListenersAttached = false;
  
  // –ù–æ–≤—ã–µ —Å–≤–æ–π—Å—Ç–≤–∞ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
  private static audioQueue: AudioQueueItem[] = [];
  private static isPlaying = false;
  private static currentSource: AudioBufferSourceNode | null = null;
  private static shouldStop = false;
  private static onPlaybackComplete: (() => void) | null = null;

  // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è
  private static initInteractionTracking(): void {
    if (this.interactionListenersAttached || typeof window === 'undefined') return;

    const updateInteraction = () => this.updateUserInteraction();

    // –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ç–∏–ø—ã –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è
    const events = ['click', 'keydown', 'touchstart', 'mousedown', 'scroll'];
    events.forEach(event => {
      window.addEventListener(event, updateInteraction, { passive: true });
    });

    // –û—Ç–º–µ—á–∞–µ–º, —á—Ç–æ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã
    this.interactionListenersAttached = true;
    console.log('üëÜ TTS interaction tracking initialized');
  }

  // –ü–æ–ª—É—á–∏—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π MIME —Ç–∏–ø –¥–ª—è –∞—É–¥–∏–æ —Ñ–æ—Ä–º–∞—Ç–∞
  private static getMimeType(format: string): string {
    switch (format) {
      case 'aac': return 'audio/aac';
      case 'mp3': return 'audio/mpeg';
      case 'opus': return 'audio/opus';
      case 'flac': return 'audio/flac';
      default: return 'audio/mpeg';
    }
  }

  // –û—á–∏—Å—Ç–∏—Ç—å —Ç–µ–∫—Å—Ç –æ—Ç —É–¥–∞—Ä–µ–Ω–∏–π –∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è TTS
  private static cleanTextForTTS(text: string): string {
    if (!text) return text;

    // –£–¥–∞–ª—è–µ–º –∑–Ω–∞–∫–∏ —É–¥–∞—Ä–µ–Ω–∏–π (+) –ø–µ—Ä–µ–¥ –≥–ª–∞—Å–Ω—ã–º–∏
    let cleaned = text.replace(/\+([–∞–µ—ë–∏–æ—É—ã—ç—é—è])/gi, '$1');

    // –£–¥–∞–ª—è–µ–º –¥—Ä—É–≥–∏–µ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –º–µ—à–∞—Ç—å TTS
    cleaned = cleaned.replace(/[¬´¬ª""''""''""]/g, ''); // –£–±–∏—Ä–∞–µ–º –∫–∞–≤—ã—á–∫–∏

    // –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
    cleaned = cleaned.replace(/\s+/g, ' ').trim();

    return cleaned;
  }

  static async generateSpeech(text: string, options: TTSOptions = {}): Promise<ArrayBuffer> {
    const {
      voice = 'alloy', // alloy - –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π –º—É–∂—Å–∫–æ–π –≥–æ–ª–æ—Å, —Ö–æ—Ä–æ—à–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ
      speed = 1.0,
      model = 'tts-1',
      format = 'mp3' // MP3 - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å–æ –≤—Å–µ–º–∏ –±—Ä–∞—É–∑–µ—Ä–∞–º–∏
    } = options;

    console.log('üé§ generateSpeech called:', {
      textLength: text.length,
      textPreview: text.substring(0, 50) + '...',
      voice,
      speed,
      model
    });

    // –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ü–∏—Ñ—Ä—ã –≤ —Å–ª–æ–≤–∞ –∏ —É–¥–∞–ª—è–µ–º —É–¥–∞—Ä–µ–Ω–∏—è (–∑–Ω–∞–∫–∏ +)
    const processedText = this.cleanTextForTTS(replaceNumbersInText(text));
    console.log('üìù Original text:', text.substring(0, 100) + '...');
    console.log('üìù Processed text:', processedText.substring(0, 100) + '...');
    console.log('üìù Text changed:', text !== processedText);

    console.log('üì° Fetching TTS from:', `${window.location.origin}/api/audio/speech`);
    const response = await fetch(`${window.location.origin}/api/audio/speech`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: model,
        input: processedText,
        voice: voice,
        response_format: format,
        speed: speed,
      }),
    });

    console.log('üì° TTS API response status:', response.status);

    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      console.error('‚ùå TTS API error:', errorData);
      throw new Error(`OpenAI TTS API error: ${response.status} ${response.statusText}. ${errorData.error?.message || ''}`);
    }

    const arrayBuffer = await response.arrayBuffer();
    console.log('‚úÖ TTS audio received, size:', arrayBuffer.byteLength, 'bytes');
    return arrayBuffer;
  }

  static async speak(text: string, options: TTSOptions = {}): Promise<void> {
    return this.speakText(text, options);
  }

  /**
   * üöÄ –ù–û–í–´–ô –ú–ï–¢–û–î: –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è TTS —Å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–º –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ–º
   * –†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ,
   * –∏ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç –ø–æ –º–µ—Ä–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏
   */
  static async speakStreaming(text: string, options: TTSOptions = {}): Promise<void> {
    console.log('üöÄ TTS Streaming: Starting parallel generation...');
    
    // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è
    this.initInteractionTracking();
    
    // –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å TTS
    if (!isTTSAvailable()) {
      console.error('‚ùå TTS not available');
      return this.fallbackToBrowserTTS(text, () => {});
    }
    
    // –ü—Ä–æ–≤–µ—Ä—è–µ–º user activation
    if (!this.hasUserActivation()) {
      console.warn('‚ö†Ô∏è No user activation for TTS');
      this.showAutoplayWarning();
      return;
    }
    
    // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—É—â–µ–µ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ
    this.stop();
    this.shouldStop = false;
    this.audioQueue = [];
    
    // –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
    const sentences = this.splitIntoSentences(text);
    console.log(`üìù TTS Streaming: Split into ${sentences.length} sentences`);
    
    if (sentences.length === 0) {
      console.warn('‚ö†Ô∏è No sentences to speak');
      return;
    }
    
    // –ï—Å–ª–∏ —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–π –º–µ—Ç–æ–¥
    if (sentences.length === 1) {
      return this.speakText(text, options);
    }
    
    // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º AudioContext
    await this.initAudioContext();
    
    return new Promise<void>(async (resolve) => {
      this.onPlaybackComplete = resolve;
      
      // –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –≤—Å–µ—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
      const generationPromises = sentences.map((sentence, index) => 
        this.generateSentenceAudio(sentence, index, options)
      );
      
      // –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –º–µ—Ä–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏
      let nextToPlay = 0;
      let completedCount = 0;
      const totalSentences = sentences.length;
      
      // –ò—Å–ø–æ–ª—å–∑—É–µ–º Promise.allSettled –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—Å–µ—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
      const results = await Promise.allSettled(generationPromises);
      
      // –°–æ—Ä—Ç–∏—Ä—É–µ–º –≥–æ—Ç–æ–≤—ã–µ –∞—É–¥–∏–æ –ø–æ –∏–Ω–¥–µ–∫—Å—É
      const readyAudios: (AudioQueueItem | null)[] = new Array(totalSentences).fill(null);
      
      for (let i = 0; i < results.length; i++) {
        const result = results[i];
        if (result.status === 'fulfilled' && result.value) {
          readyAudios[result.value.index] = result.value;
        } else {
          console.warn(`‚ö†Ô∏è Sentence ${i} generation failed`);
        }
      }
      
      // –ù–∞—á–∏–Ω–∞–µ–º –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ
      console.log('‚ñ∂Ô∏è TTS Streaming: Starting playback...');
      this.playVideo();
      
      const playNext = async () => {
        if (this.shouldStop) {
          console.log('üõë TTS Streaming: Stopped by user');
          this.pauseVideo();
          resolve();
          return;
        }
        
        while (nextToPlay < totalSentences && !readyAudios[nextToPlay]) {
          nextToPlay++;
        }
        
        if (nextToPlay >= totalSentences) {
          console.log('‚úÖ TTS Streaming: All sentences played');
          this.pauseVideo();
          this.isPlaying = false;
          resolve();
          return;
        }
        
        const audioItem = readyAudios[nextToPlay];
        if (audioItem) {
          console.log(`‚ñ∂Ô∏è Playing sentence ${nextToPlay + 1}/${totalSentences}: "${audioItem.text.substring(0, 30)}..."`);
          
          try {
            await this.playAudioBuffer(audioItem.buffer);
            nextToPlay++;
            playNext();
          } catch (error) {
            console.error(`‚ùå Error playing sentence ${nextToPlay}:`, error);
            nextToPlay++;
            playNext();
          }
        } else {
          nextToPlay++;
          playNext();
        }
      };
      
      this.isPlaying = true;
      playNext();
    });
  }
  
  /**
   * –†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–ª—è TTS
   */
  private static splitIntoSentences(text: string): string[] {
    // –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
    const cleanText = text.replace(/\s+/g, ' ').trim();
    
    // –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ –∑–Ω–∞–∫–∞–º –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è, —Å–æ—Ö—Ä–∞–Ω—è—è –∏—Ö
    const sentenceRegex = /[^.!?]+[.!?]+/g;
    const sentences = cleanText.match(sentenceRegex) || [];
    
    // –§–∏–ª—å—Ç—Ä—É–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è (–º–µ–Ω—å—à–µ 5 —Å–∏–º–≤–æ–ª–æ–≤)
    // –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ–º –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–µ —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏
    const result: string[] = [];
    
    for (const sentence of sentences) {
      const trimmed = sentence.trim();
      if (trimmed.length < 5) continue;
      
      // –ï—Å–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–æ–µ –∏ –µ—Å—Ç—å –ø—Ä–µ–¥—ã–¥—É—â–µ–µ, –æ–±—ä–µ–¥–∏–Ω—è–µ–º
      if (trimmed.length < 20 && result.length > 0) {
        result[result.length - 1] += ' ' + trimmed;
      } else {
        result.push(trimmed);
      }
    }
    
    // –ï—Å–ª–∏ –æ—Å—Ç–∞–ª—Å—è —Ç–µ–∫—Å—Ç –±–µ–∑ –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è –≤ –∫–æ–Ω—Ü–µ
    const lastMatch = cleanText.match(/[^.!?]+$/);
    if (lastMatch && lastMatch[0].trim().length > 5) {
      const remaining = lastMatch[0].trim();
      if (result.length > 0 && remaining.length < 20) {
        result[result.length - 1] += ' ' + remaining;
      } else {
        result.push(remaining);
      }
    }
    
    return result;
  }
  
  /**
   * –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ –¥–ª—è –æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
   */
  private static async generateSentenceAudio(
    sentence: string, 
    index: number, 
    options: TTSOptions
  ): Promise<AudioQueueItem | null> {
    try {
      console.log(`üé§ Generating audio for sentence ${index + 1}: "${sentence.substring(0, 30)}..."`);
      
      const startTime = Date.now();
      const arrayBuffer = await this.generateSpeech(sentence, options);
      const generationTime = Date.now() - startTime;
      
      console.log(`‚úÖ Sentence ${index + 1} generated in ${generationTime}ms, size: ${arrayBuffer.byteLength} bytes`);
      
      // –î–µ–∫–æ–¥–∏—Ä—É–µ–º –≤ AudioBuffer
      if (!this.audioContext) {
        await this.initAudioContext();
      }
      
      const audioBuffer = await new Promise<AudioBuffer>((resolve, reject) => {
        this.audioContext!.decodeAudioData(
          arrayBuffer.slice(0),
          (buffer) => resolve(buffer),
          (error) => reject(error)
        );
      });
      
      return {
        buffer: audioBuffer,
        index,
        text: sentence
      };
    } catch (error) {
      console.error(`‚ùå Failed to generate sentence ${index + 1}:`, error);
      return null;
    }
  }
  
  /**
   * –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç AudioContext
   */
  private static async initAudioContext(): Promise<void> {
    if (!this.audioContext) {
      const AudioContextClass = window.AudioContext || (window as any).webkitAudioContext;
      if (!AudioContextClass) {
        throw new Error('AudioContext not supported');
      }
      this.audioContext = new AudioContextClass();
      console.log('‚úÖ AudioContext initialized');
    }
    
    if (this.audioContext.state === 'suspended') {
      await this.audioContext.resume();
      console.log('‚úÖ AudioContext resumed');
    }
  }
  
  /**
   * –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç –æ–¥–∏–Ω AudioBuffer
   */
  private static playAudioBuffer(buffer: AudioBuffer): Promise<void> {
    return new Promise((resolve, reject) => {
      if (!this.audioContext || this.shouldStop) {
        resolve();
        return;
      }
      
      try {
        const source = this.audioContext.createBufferSource();
        source.buffer = buffer;
        source.connect(this.audioContext.destination);
        
        this.currentSource = source;
        
        source.onended = () => {
          this.currentSource = null;
          resolve();
        };
        
        source.start(0);
      } catch (error) {
        reject(error);
      }
    });
  }

  // –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ user activation (–Ω–µ–æ–±—Ö–æ–¥–∏–º–∞ –¥–ª—è autoplay)
  private static hasUserActivation(): boolean {
    // –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π API userActivation
    if (typeof navigator !== 'undefined' && 'userActivation' in navigator) {
      return (navigator as any).userActivation?.hasBeenActive || false;
    }

    // Fallback: –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –Ω–µ–¥–∞–≤–Ω–µ–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ (click, keypress, etc.)
    // –≠—Ç–æ –Ω–µ –∏–¥–µ–∞–ª—å–Ω–æ, –Ω–æ –ª—É—á—à–µ —á–µ–º –Ω–∏—á–µ–≥–æ
    const now = Date.now();
    const lastInteraction = (window as any)._ttsLastInteraction || 0;
    return (now - lastInteraction) < 5000; // 5 —Å–µ–∫—É–Ω–¥
  }

  // –ü–æ–∫–∞–∑–∞—Ç—å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ–± autoplay
  private static showAutoplayWarning(): void {
    console.warn('üîä TTS –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω –ø–æ–ª–∏—Ç–∏–∫–æ–π autoplay –±—Ä–∞—É–∑–µ—Ä–∞');
    console.warn('üí° –î–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –∑–≤—É–∫–∞ –Ω–∞–∂–º–∏—Ç–µ –Ω–∞ –ª—é–±—É—é –∫–Ω–æ–ø–∫—É –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ');

    // –ü–æ–∫–∞–∑—ã–≤–∞–µ–º toast —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ (–µ—Å–ª–∏ –µ—Å—Ç—å —Å–∏—Å—Ç–µ–º–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π)
    if (typeof window !== 'undefined' && (window as any).showToast) {
      (window as any).showToast('–î–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –≥–æ–ª–æ—Å–∞ –Ω–∞–∂–º–∏—Ç–µ –Ω–∞ –ª—é–±—É—é –∫–Ω–æ–ø–∫—É –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ', 'warning');
    }

    // –î–∏—Å–ø–∞—Ç—á–∏–º —Å–æ–±—ã—Ç–∏–µ –¥–ª—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    if (typeof window !== 'undefined') {
      window.dispatchEvent(new CustomEvent('tts-autoplay-blocked', {
        detail: { message: 'TTS –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω –ø–æ–ª–∏—Ç–∏–∫–æ–π autoplay –±—Ä–∞—É–∑–µ—Ä–∞' }
      }));
    }
  }

  // –û–±–Ω–æ–≤–∏—Ç—å –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è
  static updateUserInteraction(): void {
    if (typeof window !== 'undefined') {
      (window as any)._ttsLastInteraction = Date.now();
    }
  }

  // –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∏ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å TTS –ø–æ—Å–ª–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
  static async tryActivateTTS(): Promise<boolean> {
    console.log('üîÑ Checking TTS activation...');

    if (this.hasUserActivation()) {
      console.log('‚úÖ TTS is now activated');
      return true;
    }

    console.log('‚è≥ TTS still not activated - waiting for user interaction');
    return false;
  }

  // –ü–æ–≤—Ç–æ—Ä–Ω–æ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ—Å—Ç–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–π –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–π TTS (–ø–æ—Å–ª–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è)
  static async retryLastTTS(): Promise<void> {
    console.log('üîÑ Retrying last TTS after user interaction...');

    if (!this.hasUserActivation()) {
      console.warn('‚ö†Ô∏è Still no user activation');
      return;
    }

    // –ó–¥–µ—Å—å –º–æ–∂–Ω–æ —Ö—Ä–∞–Ω–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ç–µ–∫—Å—Ç –¥–ª—è –ø–æ–≤—Ç–æ—Ä–∞
    // –ü–æ–∫–∞ –ø—Ä–æ—Å—Ç–æ –ª–æ–≥–∏—Ä—É–µ–º
    console.log('üí° User can now use TTS normally');
  }

  static async speakText(text: string, options: TTSOptions = {}): Promise<void> {
    console.log('üéôÔ∏è OpenAI TTS speakText called with text:', text.substring(0, 50) + '...');

    // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏
    this.initInteractionTracking();

    try {
      // –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å OpenAI TTS
      if (!isTTSAvailable()) {
        console.error('‚ùå OpenAI TTS not available - missing API key or browser audio support');
        throw new Error('OpenAI TTS not available: missing API key or browser does not support Audio API');
      }

      // –ü—Ä–æ–≤–µ—Ä—è–µ–º user activation –¥–ª—è autoplay
      if (!this.hasUserActivation()) {
        console.warn('‚ö†Ô∏è No user activation detected - TTS may be blocked by browser autoplay policy');
        console.warn('üí° User needs to interact with the page first (click, tap, etc.)');

        // –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
        this.showAutoplayWarning();
        return;
      }

      console.log('‚úÖ OpenAI TTS is available');

      // Force MP3 format for OpenAI TTS compatibility
      if (!options.format) {
        options.format = 'mp3';
      }
      console.log('üéµ OpenAI TTS using format:', options.format);

      // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—É—â–µ–µ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ
      this.stop();

      // –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ—á—å
      console.log('üé§ Calling generateSpeech...');
      const audioBuffer = await this.generateSpeech(text, options);
      console.log('‚úÖ generateSpeech completed');

      // OpenAI TTS: Web Audio API is more reliable across browsers
      console.log('üéµ OpenAI TTS - Using Web Audio API...');
      console.log('üéµ Audio buffer size:', audioBuffer.byteLength, 'bytes');

      return new Promise<void>(async (resolve) => {
        const cleanup = () => {
          if (this.currentAudioUrl) {
            URL.revokeObjectURL(this.currentAudioUrl);
            this.currentAudioUrl = null;
          }
        };

        try {
          // Initialize AudioContext
          if (!this.audioContext) {
            const AudioContextClass = window.AudioContext || (window as any).webkitAudioContext;
            if (!AudioContextClass) {
              throw new Error('AudioContext not supported');
            }
            this.audioContext = new AudioContextClass();
            console.log('‚úÖ AudioContext initialized, state:', this.audioContext.state);
          }

          // Ensure AudioContext is running (required after user interaction)
          if (this.audioContext.state === 'suspended') {
            console.log('üîÑ Resuming suspended AudioContext...');
            await this.audioContext.resume();
            console.log('‚úÖ AudioContext resumed, state:', this.audioContext.state);
          }

          // Make a copy of the buffer for decoding (decodeAudioData consumes the buffer)
          const bufferCopy = audioBuffer.slice(0);
          
          // Decode audio buffer
          console.log('üîÑ Decoding audio buffer via Web Audio API...');
          
          // Use callback-based API for better Safari compatibility
          const decodedBuffer = await new Promise<AudioBuffer>((resolveBuffer, rejectBuffer) => {
            this.audioContext!.decodeAudioData(
              bufferCopy,
              (buffer) => {
                console.log('‚úÖ Audio decoded, duration:', buffer.duration.toFixed(2), 's, channels:', buffer.numberOfChannels);
                resolveBuffer(buffer);
              },
              (error) => {
                console.error('‚ùå decodeAudioData failed:', error);
                rejectBuffer(error);
              }
            );
          });

          // Create and play using Web Audio API
          const source = this.audioContext.createBufferSource();
          source.buffer = decodedBuffer;
          source.connect(this.audioContext.destination);

          source.onended = () => {
            console.log('‚úÖ OpenAI TTS playback completed');
            this.pauseVideo();
            cleanup();
            resolve();
          };

          console.log('‚ñ∂Ô∏è Starting OpenAI TTS playback...');
          source.start(0);
          this.playVideo();
          console.log('‚úÖ OpenAI TTS playback started successfully!');

        } catch (webAudioError: any) {
          console.error('‚ùå Web Audio API error:', webAudioError.message || webAudioError);
          console.log('üîÑ OpenAI TTS failed, using browser speech synthesis...');
          
          // Browser speech synthesis is the only reliable fallback
          this.fallbackToBrowserTTS(text, resolve);
          cleanup();
        }
      });

    } catch (error) {
      console.error('‚ùå OpenAI TTS error:', error);
      // Don't throw - provide visual feedback instead
      console.log('‚ö†Ô∏è TTS failed completely, providing visual feedback only');
      // Return successfully to prevent app from breaking
      return;
    }
  }

  // Web Audio API fallback for OpenAI TTS
  private static async tryWebAudioFallback(audioBuffer: ArrayBuffer, resolve: () => void, cleanup: () => void): Promise<void> {
    try {
      console.log('üîÑ OpenAI TTS: Trying Web Audio API as fallback...');

      // Initialize AudioContext for OpenAI TTS
      if (!this.audioContext) {
        this.audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
        console.log('‚úÖ AudioContext initialized for OpenAI TTS fallback');
      }

      // Ensure AudioContext is running for OpenAI TTS
      if (this.audioContext.state === 'suspended') {
        await this.audioContext.resume();
        console.log('‚úÖ AudioContext resumed for OpenAI TTS fallback');
      }

      // Decode OpenAI TTS audio buffer
      console.log('üîÑ Decoding OpenAI TTS audio buffer via Web Audio...');
      const decodedBuffer = await this.audioContext.decodeAudioData(audioBuffer.slice(0));
      console.log('‚úÖ OpenAI TTS audio decoded, duration:', decodedBuffer.duration, 'seconds');

      // Create and play OpenAI TTS using Web Audio API
      const source = this.audioContext.createBufferSource();
      source.buffer = decodedBuffer;
      source.connect(this.audioContext.destination);

      source.onended = () => {
        console.log('‚úÖ OpenAI TTS Web Audio playback completed successfully');
        this.pauseVideo();
        cleanup();
        resolve();
      };

      console.log('‚ñ∂Ô∏è üöÄ Starting OpenAI TTS playback via Web Audio API...');
      source.start(0);
      this.playVideo();
      console.log('‚úÖ OpenAI TTS Web Audio playback started - using OpenAI voice!');

    } catch (webAudioError) {
      console.warn('‚ö†Ô∏è Web Audio API fallback also failed:', webAudioError.message);
      console.log('üîÑ OpenAI TTS: Using browser speech synthesis as last resort...');

      // Final fallback: Browser speech synthesis
      this.fallbackToBrowserTTS('', resolve);
      cleanup();
    }
  }

  // –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ ArrayBuffer –≤ base64
  private static arrayBufferToBase64(buffer: ArrayBuffer): string {
    const bytes = new Uint8Array(buffer);
    let binary = '';
    const len = bytes.byteLength;
    for (let i = 0; i < len; i++) {
      binary += String.fromCharCode(bytes[i]);
    }
    return btoa(binary);
  }

  static stop(): void {
    // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–ª–∞–≥ –¥–ª—è streaming
    this.shouldStop = true;
    this.isPlaying = false;
    this.audioQueue = [];
    
    // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—É—â–∏–π AudioBufferSourceNode
    if (this.currentSource) {
      try {
        this.currentSource.stop();
      } catch (e) {
        // Ignore if already stopped
      }
      this.currentSource = null;
    }
    
    // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º HTML Audio
    if (this.currentAudio) {
      this.currentAudio.pause();
      this.currentAudio.currentTime = 0;
      this.currentAudio = null;
    }
    
    if (this.currentAudioUrl) {
      URL.revokeObjectURL(this.currentAudioUrl);
      this.currentAudioUrl = null;
    }
    
    // –í—ã–∑—ã–≤–∞–µ–º callback –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –µ—Å–ª–∏ –µ—Å—Ç—å
    if (this.onPlaybackComplete) {
      this.onPlaybackComplete();
      this.onPlaybackComplete = null;
    }
    
    this.pauseVideo();
    console.log('üõë TTS stopped');
  }

  static isPlayingAudio(): boolean {
    return this.isPlaying || (this.currentAudio !== null && !this.currentAudio.paused) || this.currentSource !== null;
  }

  // Set video element to sync with TTS
  static setVideoElement(video: HTMLVideoElement | null): void {
    this.videoElement = video;
    console.log('üé• Video element set:', !!video);
    
    // Pause video initially
    if (video) {
      video.pause();
    }
  }

  // Play video when TTS starts
  private static playVideo(): void {
    if (this.videoElement) {
      console.log('‚ñ∂Ô∏è Playing video');
      this.videoElement.play().catch((err) => {
        console.warn('‚ö†Ô∏è Could not play video:', err.message);
      });
    }
  }

  // Pause video when TTS stops
  private static pauseVideo(): void {
    if (this.videoElement) {
      console.log('‚è∏Ô∏è Pausing video');
      this.videoElement.pause();
    }
  }


  // Fallback method if MP3 fails - try browser's built-in speech synthesis
  private static async fallbackToSpeechSynthesis(text: string, resolve: () => void, reject: (error: Error) => void) {
    try {
      console.log('üîÑ Falling back to browser speech synthesis...');

      if (!('speechSynthesis' in window)) {
        console.log('‚ö†Ô∏è Speech synthesis not available in browser');
        // Don't reject - just resolve as if speech worked (silent mode)
        resolve();
        return;
      }

      const utterance = new SpeechSynthesisUtterance(text);
      utterance.lang = 'ru-RU'; // Russian language
      utterance.rate = 0.9; // Slightly slower than default
      utterance.pitch = 1.0;
      utterance.volume = 1.0;

      // Set up event handlers
      let hasStarted = false;

      utterance.onstart = () => {
        console.log('‚úÖ Speech synthesis started');
        hasStarted = true;
        this.playVideo();
      };

      utterance.onend = () => {
        console.log('‚úÖ Speech synthesis ended');
        this.pauseVideo();
        resolve();
      };

      utterance.onerror = (event) => {
        console.error('‚ùå Speech synthesis error:', event.error, event);

        // If speech synthesis fails due to autoplay policy, just resolve silently
        if (event.error === 'not-allowed' || event.error === 'interrupted') {
          console.log('‚ö†Ô∏è Speech blocked by browser policy, continuing silently');
          resolve();
        } else {
          // For other errors, still resolve but log the issue
          console.log('‚ö†Ô∏è Speech synthesis failed, continuing with visual feedback only');
          resolve();
        }
      };

      // Add timeout as safety net
      const timeout = setTimeout(() => {
        if (!hasStarted) {
          console.log('‚ö†Ô∏è Speech synthesis timeout, continuing silently');
          resolve();
        }
      }, 5000); // 5 second timeout

      utterance.onstart = () => {
        clearTimeout(timeout);
        console.log('‚úÖ Speech synthesis started');
        hasStarted = true;
        this.playVideo();
      };

      utterance.onend = () => {
        clearTimeout(timeout);
        console.log('‚úÖ Speech synthesis ended');
        this.pauseVideo();
        resolve();
      };

      console.log('üé§ Attempting to speak via browser synthesis...');
      window.speechSynthesis.speak(utterance);

    } catch (error) {
      console.error('‚ùå Speech synthesis setup failed:', error);
      // Don't reject - resolve silently so the app continues working
      console.log('‚ö†Ô∏è Speech synthesis failed, continuing with visual feedback only');
      resolve();
    }
  }

  // Final fallback to browser speech synthesis
  private static async fallbackToBrowserTTS(text: string, resolve: () => void): Promise<void> {
    try {
      console.log('üîÑ Using browser speech synthesis as fallback...');

      if (!('speechSynthesis' in window)) {
        console.warn('‚ö†Ô∏è Speech synthesis not supported in this browser');
        resolve();
        return;
      }

      // Cancel any ongoing speech
      window.speechSynthesis.cancel();

      const utterance = new SpeechSynthesisUtterance(text);
      utterance.lang = 'ru-RU';
      utterance.rate = 0.9;
      utterance.pitch = 1.0;
      utterance.volume = 1.0;

      // Find a Russian voice if available
      const voices = window.speechSynthesis.getVoices();
      const russianVoice = voices.find(v => v.lang.startsWith('ru'));
      if (russianVoice) {
        utterance.voice = russianVoice;
        console.log('üé§ Using Russian voice:', russianVoice.name);
      }

      let resolved = false;
      const safeResolve = () => {
        if (!resolved) {
          resolved = true;
          this.pauseVideo();
          resolve();
        }
      };

      utterance.onstart = () => {
        console.log('‚úÖ Browser speech synthesis started');
        this.playVideo();
      };

      utterance.onend = () => {
        console.log('‚úÖ Browser speech synthesis completed');
        safeResolve();
      };

      utterance.onerror = (event) => {
        console.warn('‚ö†Ô∏è Browser speech synthesis error:', event.error);
        safeResolve();
      };

      // Timeout safety net
      setTimeout(() => {
        if (!resolved) {
          console.warn('‚ö†Ô∏è Browser speech synthesis timeout');
          window.speechSynthesis.cancel();
          safeResolve();
        }
      }, 30000); // 30 second timeout

      window.speechSynthesis.speak(utterance);

    } catch (error) {
      console.error('‚ùå Browser speech synthesis setup error:', error);
      this.pauseVideo();
      resolve();
    }
  }

  // Fallback to speech synthesis if MP3 fails
  private static async fallbackToWAV(audioBuffer: ArrayBuffer, text: string, resolve: () => void, reject: (error: Error) => void, cleanup: () => void) {
    try {
      console.log('üîÑ Attempting speech synthesis fallback...');

      // Try speech synthesis first (more reliable)
      // Note: this function now always resolves, never rejects
      await this.fallbackToSpeechSynthesis(text, resolve, reject);
    } catch (speechError) {
      console.error('‚ùå All audio fallbacks failed');
      // Resolve anyway to prevent app from breaking
      console.log('‚ö†Ô∏è All audio methods failed, continuing with visual feedback only');
      resolve();
    }
  }
}

// –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –∞—É–¥–∏–æ —Ñ–æ—Ä–º–∞—Ç–∞
export async function isAudioFormatSupported(format: string): Promise<boolean> {
  if (typeof Audio === 'undefined') return false;

  try {
    const audio = new Audio();
    const mimeType = format === 'aac' ? 'audio/aac' :
                     format === 'mp3' ? 'audio/mpeg' :
                     format === 'opus' ? 'audio/opus' :
                     format === 'flac' ? 'audio/flac' : 'audio/mpeg';

    const canPlay = audio.canPlayType(mimeType);
    console.log(`üéµ Format ${format} (${mimeType}) support:`, canPlay);
    return canPlay !== '';
  } catch (error) {
    console.warn('Error checking audio format support:', error);
    return false;
  }
}

// –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ª—É—á—à–µ–≥–æ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞
export async function getBestSupportedFormat(): Promise<string> {
  // MP3 is the most compatible format for Blob URLs across all browsers
  const formats = ['mp3', 'aac', 'opus', 'flac'];

  for (const format of formats) {
    if (await isAudioFormatSupported(format)) {
      console.log(`‚úÖ Best supported format: ${format}`);
      return format;
    }
  }

  console.warn('‚ùå No supported audio formats found, using mp3 as fallback');
  return 'mp3'; // fallback
}

// –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ TTS
export function isTTSAvailable(): boolean {
  // –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∫—É Audio API –≤ –±—Ä–∞—É–∑–µ—Ä–µ
  // API –∫–ª—é—á –ø—Ä–æ–≤–µ—Ä—è–µ—Ç—Å—è –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ –ø—Ä–∏ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–º –∑–∞–ø—Ä–æ—Å–µ
  const hasAudioSupport = typeof Audio !== 'undefined' &&
                         typeof AudioContext !== 'undefined' &&
                         typeof window !== 'undefined' &&
                         typeof fetch !== 'undefined';

  return hasAudioSupport;
}

// –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏, —Ä–∞–∑—Ä–µ—à–µ–Ω–æ –ª–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –∞—É–¥–∏–æ
export async function isAutoplayAllowed(): Promise<boolean> {
  if (typeof Audio === 'undefined') return false;

  try {
    const audio = new Audio();
    audio.volume = 0.01; // –û—á–µ–Ω—å —Ç–∏—Ö–∏–π –∑–≤—É–∫ –¥–ª—è —Ç–µ—Å—Ç–∞
    audio.muted = true;

    // –ü—ã—Ç–∞–µ–º—Å—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ—Å—Ç–∏
    await audio.play();
    audio.pause();
    return true;
  } catch (error) {
    return false;
  }
}

// –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –∞—É–¥–∏–æ –ø–æ—Å–ª–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è
export function activateAudio(): Promise<void> {
  return new Promise(async (resolve, reject) => {
    try {
      console.log('üîä Activating audio context...');

      // Multiple attempts to activate audio
      const activationPromises = [];

      // 1. Activate AudioContext
      if (typeof AudioContext !== 'undefined' || typeof webkitAudioContext !== 'undefined') {
        const activationPromise = (async () => {
          try {
            const AudioContextClass = AudioContext || webkitAudioContext;
            const audioContext = new AudioContextClass();

            if (audioContext.state === 'suspended') {
              await audioContext.resume();
              console.log('‚úÖ AudioContext activated');
            }

            // Test with a short beep
            const oscillator = audioContext.createOscillator();
            const gainNode = audioContext.createGain();

            oscillator.connect(gainNode);
            gainNode.connect(audioContext.destination);

            oscillator.frequency.setValueAtTime(440, audioContext.currentTime);
            oscillator.type = 'sine';
            gainNode.gain.setValueAtTime(0.01, audioContext.currentTime);

            oscillator.start(audioContext.currentTime);
            oscillator.stop(audioContext.currentTime + 0.1);

            return true;
          } catch (error) {
            console.warn('‚ö†Ô∏è AudioContext activation failed:', error);
            return false;
          }
        })();
        activationPromises.push(activationPromise);
      }

      // 2. Test HTML Audio multiple times
      for (let i = 0; i < 3; i++) {
        const htmlAudioPromise = (async () => {
          try {
            const testAudio = new Audio();
            testAudio.volume = 0.01;
            testAudio.muted = true;
            testAudio.src = 'data:audio/wav;base64,UklGRigAAABXQVZFZm10IBIAAAABAAEARKwAAIhYAQACABAAAABkYXRhAgAAAAEA';

            return new Promise<boolean>((resolveAudio) => {
              testAudio.onended = () => {
                console.log(`‚úÖ HTML Audio test ${i + 1} successful`);
                resolveAudio(true);
              };

              testAudio.onerror = () => {
                console.log(`‚ö†Ô∏è HTML Audio test ${i + 1} failed`);
                resolveAudio(false);
              };

              testAudio.play().catch(() => {
                console.log(`‚ö†Ô∏è HTML Audio play ${i + 1} failed`);
                resolveAudio(false);
              });

              // Timeout fallback
              setTimeout(() => resolveAudio(false), 1000);
            });
          } catch (error) {
            console.log(`‚ö†Ô∏è HTML Audio setup ${i + 1} failed:`, error);
            return false;
          }
        })();
        activationPromises.push(htmlAudioPromise);
      }

      // 3. Test speech synthesis
      const speechPromise = (async () => {
        try {
          if ('speechSynthesis' in window) {
            const utterance = new SpeechSynthesisUtterance('test');
            utterance.volume = 0.01;
            utterance.lang = 'ru-RU';

            return new Promise<boolean>((resolveSpeech) => {
              utterance.onstart = () => {
                console.log('‚úÖ Speech synthesis test successful');
                resolveSpeech(true);
              };

              utterance.onend = () => {
                console.log('‚úÖ Speech synthesis test completed');
                resolveSpeech(true);
              };

              utterance.onerror = () => {
                console.log('‚ö†Ô∏è Speech synthesis test failed');
                resolveSpeech(false);
              };

              window.speechSynthesis.speak(utterance);

              // Timeout fallback
              setTimeout(() => resolveSpeech(false), 2000);
            });
          }
          return false;
        } catch (error) {
          console.log('‚ö†Ô∏è Speech synthesis setup failed:', error);
          return false;
        }
      })();
      activationPromises.push(speechPromise);

      // Wait for all activation attempts
      const results = await Promise.all(activationPromises);
      const successCount = results.filter(Boolean).length;

      console.log(`üîä Audio activation results: ${successCount}/${results.length} successful`);

      if (successCount > 0) {
        console.log('‚úÖ Audio activation completed successfully');
        resolve();
      } else {
        console.log('‚ö†Ô∏è All audio activation methods failed');
        resolve(); // Still resolve to continue app functionality
      }

    } catch (error) {
      console.error('‚ùå Audio activation error:', error);
      // Always resolve to prevent app from breaking
      console.log('‚ö†Ô∏è Audio activation failed, continuing without audio');
      resolve();
    }
  });
}
